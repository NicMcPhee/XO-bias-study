% Research Paper for GECCO 2015
% by Nic McPhee, Kirbie Dramdahl, and David Donatucci

\documentclass{sig-alternate}

\usepackage{parskip}
\usepackage{times} %For typeface
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithm,algorithmic}
\usepackage[justification=centering]{caption}[2007/12/23]
\usepackage{url}
\sloppy

\setlength{\parindent}{0.5cm} 

\newcommand{\citep}[1]{\cite{#1}}

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\begin{document}

\conferenceinfo{GECCO'15,} {July 11-15, 2015, Madrid, Spain.}
\CopyrightYear{2015}
\crdata{TBA}
\clubpenalty=10000
\widowpenalty = 10000
    
\title{Impact of Crossover Bias in Genetic Programming}

\numberofauthors{1}
\author{
\alignauthor
Nicholas Freitag McPhee, M. Kirbie Dramdahl, David Donatucci\\
	\affaddr{Division of Science and Mathematics}\\
	\affaddr{University of Minnesota, Morris}\\
	\affaddr{Morris, MN USA-56267}\\
	\email{\{mcphee, dramd002, donat056\}@morris.umn.edu}
}

% This is more like how it "should" be done, but I think the previous approach might look nicer. They
% may force us to change it, though, to make it easier to scrape information.

%\numberofauthors{3}
%\author{
%\alignauthor
%Nicholas Freitag McPhee\\
%	\affaddr{Division of Science and Mathematics}\\
%	\affaddr{University of Minnesota, Morris}\\
%	\affaddr{Morris, MN USA-56267}\\
%	\email{mcphee@morris.umn.edu}
%\alignauthor
%M. Kirbie Dramdahl\\
%	\affaddr{Division of Science and Mathematics}\\
%	\affaddr{University of Minnesota, Morris}\\
%	\affaddr{Morris, MN USA-56267}\\
%	\email{dramd002@morris.umn.edu}
%\alignauthor
%David Donatucci\\
%	\affaddr{Division of Science and Mathematics}\\
%	\affaddr{University of Minnesota, Morris}\\
%	\affaddr{Morris, MN USA-56267}\\
%	\email{donat056@morris.umn.edu}
%}

\date{} 
    
\maketitle

\begin{abstract}

\emph{\scriptsize This is probably too long. People often recommend keeping the abstract to somewhere 
between 150 and 250 words, and this is closer to 500. For the initial submission that's OK, but we may want 
to move some of this to the introduction and trim down the abstract somewhat.}

In tree-based genetic programming with sub-tree crossover, the parent contributing the root portion of the tree 
(which 
we refer to as the \emph{root parent}) often contributes more to the semantics of the resulting child than the 
other parent (the 
\emph{non-root parent}). In previous research, we found that when the root parent had greater fitness 
than the 
non-root parent, the fitness of the child tended to be better than if the reverse were true. Here we explore the 
significance of that asymmetry by introducing the notion of \emph{crossover bias}, which allows us to bias the 
system 
in favor of having the more fit parent be the root parent. To better understand the impact of this bias, 
we implemented several levels 
of 
crossover bias, including 0\% bias 
(root individual chosen randomly, as in traditional sub-tree crossover), 
100\% bias (the stronger parent is always chosen to be the root parent), 
50\% bias 
(bias implemented in half 
the cases, and the other half chosen randomly), and reverse bias (the weaker parent is always chosen 
as root parent). 

We applied crossover bias to a variety of problems. In most cases we found that using crossover bias 
either improved performance or had no impact. 
Our results do, however, indicate the possibility that 
crossover bias may increase selection pressure and premature convergence -- undesirable behavior, as it 
encourages a genetic programming run to arrive at a solution too quickly, in the process potentially excluding 
more accurate solutions for a more generalized one.

Our results also demonstrate that the effectiveness of 
crossover bias is somewhat dependent on the problem, and significantly dependent on other parameter 
choices. In 
particular it appears that crossover bias has the largest impact when selection pressure is weaker, and the 
differences 
in the fitness of the parents is thus likely to be larger. We also found that the use of elitism 
reduced the influence of crossover bias. It's possible that crossover bias acts to some degree as an 
``elitism'' operator, making it more likely that the semantics of more fit individuals are copied into the next 
generation; 
thus if traditional elitism is being employed this effect is less visible. Another possible explanation for this is 
that if the most fit individuals are automatically being carried over, there is perhaps less need to produce new, 
fitter individuals via crossover, reducing or even eliminating the usefulness of crossover bias. Other factors 
which we found to have potential impact on the effectiveness of crossover bias were tournament size, 
population size, and possibly the difference in parental fitness.

\end{abstract}

\category{}{}{}
\terms{}
\keywords{genetic programming, crossover bias, root parent}

\section{Introduction} \label{sec:Introduction}

\textbf{Nic should try to capture some nice things Lee Spector said about the importance of asymmetrical 
recombination operators (which are very common in biology, e.g., sex-linked traits) and how we've identified an 
asymmetry in subtree crossover and a way to potentially exploit that.}

\section{Crossover bias} \label{sec:XObias}

\section{Experimental Setup} \label{sec:Experiments}

\section{Results} \label{sec:Results}

\subsection{Structural problems}

\subsubsection{K-Landscapes problems}

We did a full sweep of parameters for the K-Landscapes problem with both $K=2$ and $K=6$.

\begin{itemize}
	\item XO bias of reverse, 0, 0.25, 0.5, 0.75, and 1
	\item Population sizes of 1,024 and 10,240
	\item Elitism of 0\% or 1\%
	\item Tournament sizes of 2, 3, 5, and 7
\end{itemize}

Figure~\ref{fig:KLandscapes6_results} shows the impact of crossover bias on this problem across all the 
combinations of parameter values. Increasing the amount of crossover bias consistently improves the 
fitness of the results. All the differences are statistically significant ($p < 0.012$) except for the difference between
between bias probability 0.75 and 1.0.

%> pairwise.wilcox.test(klandscapes6$Fitness, klandscapes6$Bias.probability)
%
%	Pairwise comparisons using Wilcoxon rank sum test 
%
%data:  klandscapes6$Fitness and klandscapes6$Bias.probability 
%
%     -1      0       0.25    0.5     0.75   
%0    0.99997 -       -       -       -      
%0.25 1.8e-06 1.8e-06 -       -       -      
%0.5  1.7e-12 2.3e-12 0.01136 -       -      
%0.75 < 2e-16 < 2e-16 6.0e-10 0.00032 -      
%1    < 2e-16 < 2e-16 3.7e-15 2.2e-07 0.15773
%
%P value adjustment method: holm 

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/KLandscapes6_XO_bias_impact_transformed_boxplot_alpha075.pdf}
\caption{Impact of crossover bias on fitness for K-Landscapes problem, $K=6$ for a variety of treatments.}
\label{fig:KLandscapes6_results}
\end{figure}

Figure~\ref{fig:KLandscapes6_strong_results} shows the subset set of this information with just binary tournament 
selection, no elitism, and population size of 10,240. It's clear that the impact of crossover bias is much stronger in this 
case than in the more general case shown in Figure~\ref{fig:KLandscapes6_results}. Here all the differences are strongly 
statistically significant ($p < 10^{-11}$) except for the difference between reverse bias (-1) and no bias (0). Increasing 
the crossover bias increases the number of ``perfect'' solutions discovered as well as just increasing the fitness. 15 
solutions were discovered in the 100 runs with crossover bias at 1.0, where only 1 or 2 solutions were discovered for 
each of the other crossover bias probabilities; this difference is statistically significant with $p \leq 0.03$ using a 
pairwise test of proportions.

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/KLandscapes6_XO_bias_strong_impact_alpha_075.pdf}
\caption{Impact of crossover bias on fitness for K-Landscapes problem, $K=6$, restricted to binary tournament 
selection, no elitism, and population size 10,240.}
\label{fig:KLandscapes6_strong_results}
\end{figure}

%> pairwise.wilcox.test(strong$Fitness, strong$Bias.probability)
%
%	Pairwise comparisons using Wilcoxon rank sum test 
%
%data:  strong$Fitness and strong$Bias.probability 
%
%     -1      0       0.25    0.5     0.75   
%0    0.18    -       -       -       -      
%0.25 < 2e-16 < 2e-16 -       -       -      
%0.5  < 2e-16 < 2e-16 < 2e-16 -       -      
%0.75 < 2e-16 < 2e-16 < 2e-16 < 2e-16 -      
%1    < 2e-16 < 2e-16 < 2e-16 < 2e-16 2.3e-12
%
%P value adjustment method: holm 

%> countSuccesses(strong)
%[1]  1  2  2  1  2 15
%> pairwise.prop.test(countSuccesses(strong), rep(100, 6))
%
%	Pairwise comparisons using Pairwise comparison of proportions 
%
%data:  countSuccesses(strong) out of rep(100, 6) 
%
%  1     2     3     4     5    
%2 1.000 -     -     -     -    
%3 1.000 1.000 -     -     -    
%4 1.000 1.000 1.000 -     -    
%5 1.000 1.000 1.000 1.000 -    
%6 0.011 0.030 0.030 0.011 0.030
%
%P value adjustment method: holm 

\subsubsection{Order tree problem}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Ordertree_results.png}
\caption{Impact of crossover bias on fitness for Ordertree problem for various tournament sizes. \textbf{Redraw this as PDF and mention how improvement drops as tournament sizes grow.}}
\label{fig:Ordertree_results}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Ordertree_XO_bias_prob_binary_tournaments.png}
\caption{Impact of crossover bias on fitness for Ordertree problem for binary tournaments.}
\label{fig:Ordertree_results_binary_tournaments}
\end{figure}

\subsubsection{Lid problem}

\textbf{We need to add plots for this problem.}

\subsection{U.S. Change problem}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/US_change_hits.png}
\caption{Impact of crossover bias on the number of hits for the US Change problem.}
\label{fig:USChange_Hits}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/US_change_hits_tourny2_noElitism.png}
\caption{Impact of crossover bias on the number of hits for the US Change problem, limited to binary 
tournaments and no elitism.}
\label{fig:USChange_Hits_tourny2_noElitism}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/US_change_successes_tourny2_noElitism.png}
\caption{Impact of crossover bias on the number of successes runs for the US Change problem, limited to 
binary tournaments and no elitism.}
\label{fig:USChange_Successes}
\end{figure}


\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/US_change_Bias_impact_vs_success.png}
\caption{Relationship between proportion of successful runs and the impact of crossover bias.}
\label{fig:USChangeBiasImpactVsSuccess}
\end{figure}

\subsection{Symbolic regression problems}

\subsubsection{Sine problem}

Figure~\ref{fig:sineBiasResultsStrong} shows the hits results for the sine regression problem (without reverse bias -- I 
think I figured we were going to drop it when I ran these.) with the ``strong treatment'', i.e., binary tournaments, no 
elitism, and the large population (10,240). Figure~\ref{fig:sineBiasResultsStrongViolin} is the same 
data, but with violin plots instead of box plots. All these differences are statistically significant ($p < 10^{-5}$ using a 
pairwise Wilcoxon rank sum test) except for the difference between the bias of 0.75 and 1.0. Figure~
\ref{fig:sineBiasFitnessResultsStrongViolin} shows the same results, but for fitness (probably sum of error?) instead of 
hits. Again, all of these are significant except for bias of 0.75 and 1.0.

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_XO_impact_strong_boxplot.pdf}
\caption{Impact of crossover bias on the sine symbolic regression problem with binary tournaments, no elitism, and 
population size 10,240}
\label{fig:sineBiasResultsStrong}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_XO_impact_strong_violin.pdf}
\caption{Impact of crossover bias on the sine symbolic regression problem with binary tournaments, no elitism, and 
population size 10,240}
\label{fig:sineBiasResultsStrongViolin}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_XO_impact_fitness_strong_violin.pdf}
\caption{Impact of crossover bias on the sine symbolic regression problem with binary tournaments, no elitism, and 
population size 10,240}
\label{fig:sineBiasFitnessResultsStrongViolin}
\end{figure}

%> pairwise.wilcox.test(sine_strong_final$Hits, sine_strong_final$Bias)
%
%	Pairwise comparisons using Wilcoxon rank sum test 
%
%data:  sine_strong_final$Hits and sine_strong_final$Bias 
%
%     0       0.25    0.5     0.75  
%0.25 1.9e-07 -       -       -     
%0.5  4.0e-15 0.0017  -       -     
%0.75 < 2e-16 1.2e-12 8.9e-06 -     
%1    < 2e-16 1.3e-13 2.9e-07 0.1938
%
%P value adjustment method: holm 

%> pairwise.wilcox.test(sine_strong_final$Standardized.fitness, sine_strong_final$Bias)
%
%	Pairwise comparisons using Wilcoxon rank sum test 
%
%data:  sine_strong_final$Standardized.fitness and sine_strong_final$Bias 
%
%     0       0.25    0.5     0.75 
%0.25 3.6e-10 -       -       -    
%0.5  < 2e-16 2.7e-05 -       -    
%0.75 < 2e-16 5.0e-14 1.1e-05 -    
%1    < 2e-16 < 2e-16 2.9e-09 0.072
%
%P value adjustment method: holm 

Figure~\ref{fig:sineBiasResultsWeak} shows the results for the sine regression problem (without reverse bias -- I 
think I figured we were going to drop it when I ran these.) with the ``weak treatment'', i.e., tournament size 7, 0.1\% 
elitism, and the small population (1,024). Figure~\ref{fig:sineBiasResultsWeakViolin} is the same 
data, but with violin plots instead of box plots. None of these differences are statistically significant using a 
pairwise Wilcoxon rank sum test. Figure~\ref{fig:sineBiasFitnessResultsWeakViolin} shows the same results, but for fitness (probably sum of error?) instead of hits. None of these differences are significant.

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_XO_impact_weak_boxplot.pdf}
\caption{Impact of crossover bias on the sine symbolic regression problem with tournament size 7, 0.1\% elitism, and 
population size 1,024.}
\label{fig:sineBiasResultsWeak}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_XO_impact_weak_violin.pdf}
\caption{Impact of crossover bias on the sine symbolic regression problem with tournament size 7, 0.1\% elitism, and 
population size 1,024.}
\label{fig:sineBiasResultsWeakViolin}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_XO_impact_fitness_weak_violin.pdf}
\caption{Impact of crossover bias on the sine symbolic regression problem with tournament size 7, 0.1\% elitism, and 
population size 1,024.}
\label{fig:sineBiasFitnessResultsWeakViolin}
\end{figure}

Figures~\ref{fig:sineBiasFitnessVsGenStrong} and~\ref{fig:sineBiasFitnessVsGenWeak} show the change in fitness 
over time for the strong and weak configurations. Figure~\ref{fig:sineBiasFitnessVsGenT2E01P10K} shows fitness over 
time for the ``weak'' configuration with population size 10,240 (instead of 1,024 for the ``normal'' weak configuration). 
Increasing the pop size definitely improves the performance by quite a lot (no surprise). The different bias levels are all 
essentially the same at the end of the 100 generations, but interestingly there is definitely a spread around 15-20 
generations that is a really clean ``more bias is better'' demonstration except for the fact that 0.75 and 1.0 are 
essentially the same.

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_XO_fitness_vs_gen_strong.pdf}
\caption{Impact of crossover bias on the sine symbolic regression problem with binary tournaments, no elitism, and 
population size 10,240.}
\label{fig:sineBiasFitnessVsGenStrong}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_XO_fitness_vs_gen_weak.pdf}
\caption{Impact of crossover bias on the sine symbolic regression problem with tournament size 7, 0.1\% elitism, and 
population size 1,024.}
\label{fig:sineBiasFitnessVsGenWeak}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_XO_fitness_vs_gen_t2_e01_p10K.pdf}
\caption{Impact of crossover bias on the sine symbolic regression problem with tournament size 7, 0.1\% elitism, and 
population size 10,240.}
\label{fig:sineBiasFitnessVsGenT2E01P10K}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_bias_results.png}
\caption{\textbf{OLD FIGURE} Impact of crossover bias on the sine symbolic regression problem}
\label{fig:sineBiasResults}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Sine_generations.png}
\caption{\textbf{OLD FIGURE} Impact of crossover bias on the fitness over time for the sine symbolic regression problem}
\label{fig:sineFitnessOverTime}
\end{figure}

\subsubsection{Pagie-1 problem}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Pagie-1_fitness_vs_time.png}
\caption{Impact of crossover bias on the fitness over time for the Pagie-1 symbolic regression problem}
\label{fig:Pagie1FitnessOverTime}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Pagie-1_size_vs_time.png}
\caption{Impact of crossover bias on the tree size over time for the Pagie-1 symbolic regression problem}
\label{fig:Pagie1SizeOverTime}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Pagie-1_Hits_vs_Bias.png}
\caption{Impact of crossover bias on the number of hits for the Pagie-1 symbolic regression problem. 
Unfortunately I'm not immediately sure what (sub)set of data this includes.}
\label{fig:Pagie1Hits}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Pagie-1_Successes_vs_Bias.png}
\caption{Impact of crossover bias on the number of successes (runs that exactly solve the problem) for the 
Pagie-1 symbolic regression problem. Unfortunately I'm not immediately sure what (sub)set of data this 
includes.}
\label{fig:Pagie1Successes}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Pagie-1-koza2_no_Tarpeian.png}
\caption{Impact of crossover bias on the number of hits when using the koza2 function set for the Pagie-1 
symbolic regression problem.}
\label{fig:Pagie1Koza2}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Pagie-1-tarp.png}
\caption{Impact of crossover bias on the number of hits when using the koza2 function set and Tarpeian bloat 
control for the Pagie-1 symbolic regression problem.}
\label{fig:Pagie1Koza2Tarpeian}
\end{figure}

\subsection{Santa Fe Trail problem}

\textbf{We agreed to drop this problem rather than spend time on it.}

I did this small-ish set of runs early on, so the setup for this isn't really the same as for the later problems. The 
only ``parameter sweep'' I did was XO bias on (i.e., 1) or off (i.e., 0). I only ran 50 generations, and the setting 
to stop early if a solution was found was turned on, so not all the runs went out to 50 generations. There were 
200 runs total, 100 with bias and 100 without. The population sizes are 4,096 and the tournament size is the ECJ 
default of 7; there's no elitism or Tarpeian bloat control.

These were early runs of the ant problem on the cluster. There are only 50 generations, and all we (currently) have is 
bias off and bias fully on (i.e., bias rate of either 0 or 1). The population sizes are 4096 (instead of either 1,024 or 
10,240 as on most of the other problems). The tournament size is the ECJ default (7), and thereÕs no elitism or 
Tarpeian bloat control.

As we can see in Figure~\ref{fig:SantaFeTrailHits}, using crossover bias on this problem appears to reduce the 
number of hits; this difference isn't statistically significant, however. ($p$-value of 0.2003 using a Wilcoxon rank sum 
test.) There are 39 successes without crossover bias, i.e., 39 out of 100 runs attained the best fitness of 89 hits, and 
31 with crossover bias. This is also not statistically significant ($p$-value of 0.2994 using a 2-sample test for equality 
of proportions).

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/SantaFeTrail_XO_Bias_boxplot.pdf}
\caption{Impact of crossover bias on the number of hits for the Santa Fe Trail problem; the difference isn't statistically 
significant.}
\label{fig:SantaFeTrailHits}
\end{figure}

Figure~\ref{fig:SantaFeTrailHitsVsGeneration} shows the hits over time, although it's skewed because runs that found 
the solution terminated early and thus ``disappear'' from this plot. It does, however, suggest that using crossover bias 
may be causing premature convergence that is limiting the ability to continue exploring and find a solution.

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/SantaFeTrail_Hits_vs_Generation.pdf}
\caption{Number of hits over time for the Santa Fe Trail problem, both with and without crossover bias. This plot is 
skewed because runs that found the solution (89 hits) ended early, and thus ``disappear'' from the plot. This explains 
the slight dip in the line for runs with crossover bias turned on (the \emph{true} line) towards the end.}
\label{fig:SantaFeTrailHitsVsGeneration}
\end{figure}

\textbf{These results really don't tell us anything since none of the differences are statistically significant. Given what 
we've learned in other places, we could re-run these with small tournaments and larger populations. That would 
certainly be more consistent with our other runs, and it might turn up something interesting. Or we could just decide 
we don't care about this problem (it's not a particularly favored problem these days, and not recommended in the 
benchmarks paper) and drop all this. Thoughts?}

\section{Discussion} \label{sec:Discussion}

Why does all this happen this way? For example, why does crossover bias have a much stronger effect when using 
binary tournaments than when using larger tournament sizes such as 7. One possible explanation is that with large 
tournaments, the difference in fitness between the two parents is likely to be closer, because the larger tournaments 
help ensure that both parents are from the more highly fit part of the population. To better understand this, blah, blah, 
blah \textbf{We need to turn this into actual text}.

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Parent_errors_sine.pdf}
\caption{Plot of the errors of all individuals chosen as parents from some sine runs. \textbf{Explain this.} \textbf{Do we want/need this plot?}}
\label{fig:parentErrorsSine}
\end{figure}

Figure~\ref{fig:parentDiffsSine} shows the distribution of relative difference in parent errors in the sine regression 
problem. For each crossover event, the relative difference in parent errors is
\[
	|e_A - e_B] / (e_A + e_B)
\]
where $e_A$ and $e_B$ are the errors of the two chosen parents $A$ and $B$. This has a minimum value of 0 when 
the two errors are the same, and a maximum value approaching 1 for the case where one of the errors is nearly 0.

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Parent_normalized_error_diffs_sine.pdf}
\caption{Plot of the normalized differences in parent errors from some sine runs. \textbf{Explain this}.}
\label{fig:parentDiffsSine}
\end{figure}

We see similar results for the K-Landscapes problem, as illustrated in Figures~\ref{fig:parentFitnessesKLandscapes} and~\ref{fig:parentDiffsKLandscapes}.

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Parent_fitnesses_KLandscapes.pdf}
\caption{Plot of the fitnesses of all individuals chosen as parents from some K-Landscape runs. \textbf{Explain this.} \textbf{Do we want/need this plot?}}
\label{fig:parentFitnessesKLandscapes}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.45 \textwidth]{Plots/Parent_normalized_fitness_diffs_KLandscapes.pdf}
\caption{Plot of the normalized differences in parent fitnesses from some K-Landscape runs. \textbf{Explain this}.}
\label{fig:parentDiffsKLandscapes}
\end{figure}

\section{Conclusions} \label{sec:Conclusions}

In most of these experiments we found better results with tournament sizes of 7 than with binary tournaments, and in 
general using larger tournaments appears to wash out much of the impact of crossover bias, so there's a fair question 
about whether one should just use larger tournaments and ignore crossover bias. \textbf{How do we respond to this? I 
think the answer is something like ``It doesn't hurt (at least in our experiments), and it sometimes helps, even for 
tournament size 7 and with elitism. For interesting problems, you also don't know in advance what your best parameter 
choices are, so it's at least worth including in your arsenal.''}

\section*{Acknowledgements}

\bibliographystyle{acm}
\bibliography{Research_2015}

\end{document}